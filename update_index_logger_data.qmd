---
title: "Update Index Logger Data Main File"
format: html
embed-resources: true
toc: true
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

# Overview

Use this script to update the main index site logger data file when new
data becomes available.

# Requirements

## Drive Organization and File Naming

Folder structure in Drive must match this format:

```         
.
└── csvfiles/
    ├── Temperatue/
    │   ├── SiteName_LoggerNickname_Deployment-date.csv
    │   └── ex: SquaxinIsland_T4_2024-04-20.csv
    ├── pH/
    │   ├── SiteName_LoggerNickname_Deployment-date.csv
    │   └── ex: Magnolia_PH11_2024-04-20.csv
    ├── Water Level/
    │   ├── SiteName_LoggerNickname_Deployment-date.csv
    │   └── ex: PointVashon_WL3_2024-04-20.csv
    └── ...etc
```

Here, the root folder is `csvfiles/`, with sub-folders corresponding to
the sensor types. While the name of the root folder can be changed, it
is important that the sub files are named `Temperature`, `pH`,
`Water Level`, `Dissolved Oxygen`, `Conductivity`, and `PAR` (case
insensitive).

Within each sub-folder, each file to be processed needs to follow the
naming convention: `SiteName_LoggerNickname_Deployment-date.csv`

Where:

-   `SiteName` is the full site name with each new word capitalized

-   `LoggerNickname` is the nickname given to that specific instrument
    in the metadata sheet

-   `Deployment-date` in the format yyyy-mm-dd is EITHER:

    -   Date deployed or

    -   Date re-launched (whichever corresponds to the start of true
        data in that file)

-   File needs to end in `.csv`

-   Each part is separated by an underscore `_`

## Metadata sheet

It is important that the `SiteName`, `LoggerNickname`, and
`Deployment-date` are found in the metadata. This is how the code will
find more information about each file! Ensure that these 3 parts are
found in metadata columns `Site`, `Nickname`, and either
`Initial Deployment Date` or `RelaunchDate`, respectively.

# Update the Main Data File

## Step 1: Setup

First we will load the necessary packages for processing. Run this code
chunk before taking any other steps (you may need to install packages
using `install.packages("package-name-here")` if you haven't done so
already):

```{r}
# For interacting directly with Google Drive
library(googledrive)
library(googlesheets4)

# For data cleaning and manipulation
library(tidyverse)
library(janitor)
library(lubridate)
library(here)

# We also need to source our functions
source("index_data_processing_functions.r")
```

If it is your first time connecting to the Google Drive API, you will
need to authenticate your account. Run these two lines one by one and
follow the instructions in your Console:

```{r}
# Authenticate with Google Drive (only need to do this once)
# drive_auth()
# gs4_auth()
```

## Step 2: Specify Parameters

Replace the values in the quotation marks `" "` if necessary.

```{r}
########## PSRF Sites ##########
# Folder to search in for logger files. Currently named "csvfiles" in Drive
# Folder ID found after the final / in the folder's URL
root_folder_id = "1k5u8iOhR5alnymc7BVU-JJjcSnQStgWv"

# Link to the metadata sheet
metadata_file_url = "https://docs.google.com/spreadsheets/d/1JJ4Vtb_pI9FJRvMYg7pbhQzM6JPcFzGVU3rR9IdYnGQ/edit?gid=1334564098#gid=1334564098"

# Name of the tab with the file metadata
sheet_name = " Deployments_IndexOnly"


########## Reef Check Sites ##########
# # Folder to search in for logger files. Currently named "CSV" in Drive
# # Folder ID found after the final / in the folder's URL
# root_folder_id = "1fvtprLxnCWSH3EQ3DUC4cyvgUGvPBGeN"
# 
# # Full link to the metadata sheet
# metadata_file_url = "https://docs.google.com/spreadsheets/d/1-p-RWjFonTMefs3JIqPIOhIjcWqFwmQ9sE6ty4WEkOg/edit?gid=0#gid=0"
# 
# # Name of the tab with the file metadata
# sheet_name = "Deployments"

########## Point Defiance Zoo & Aquarium Sites ##########
# # Folder to search in for logger files. Currently named "CSV" in Drive
# # Folder ID found after the final / in the folder's URL
# root_folder_id = "17jpThnU1QRwp3Tq09XacaQS9fQKnYxRv"
# 
# # Full link to the metadata sheet
# metadata_file_url = "https://docs.google.com/spreadsheets/d/1QBCwXV7_KCdYab-zWmXJXDDACZXpJVtLNQuzltwy3fs/edit?gid=0#gid=0"
# 
# # Name of the tab with the file metadata
# sheet_name = "Deployments"


########## Friday Harbor Labs Sites ##########
# # Folder to search in for logger files. Currently named "CSV" in Drive
# # Folder ID found after the final / in the folder's URL
# root_folder_id = "1ZR9EpXXhPtk-9R6eyDI-wzs-m0My36c0"
# 
# # Full link to the metadata sheet
# metadata_file_url = "https://docs.google.com/spreadsheets/d/1xQ_MkgwL1-ewZWO1tq8LaTLUHW-YOx2nVj_cQ7sz4pw/edit?gid=0#gid=0"
# 
# # Name of the tab with the file metadata
# sheet_name = "Deployments"
```

## Step 3: Update File

Use the next chunk of code to update the kelp index site's logger data
from the Google Drive. Choose how you would like to update the data,
highlight that code with your mouse and un-comment (remove the `#`)
using `command + shift + c` on mac or `ctrl + shift + c` on PC, then run
the line by placing your cursor after the closing parenthesis `)` and
pushing `command + return` on mac or `ctrl + enter` on pc.

```{r}
########## Add new files to existing file ##########

data <- update_logger_data_incremental(root_folder_id = root_folder_id,
                                       metadata_file_url = metadata_file_url,
                                       sheet_name = sheet_name)




########## Re-process all old files in addition to new files  ##########

# data <- update_logger_data_incremental(root_folder_id = root_folder_id,
#                                        metadata_file_url = metadata_file_url,
#                                        sheet_name = sheet_name,
#                                        force_reprocess = TRUE)
```

## Step 4: Export as CSV to Google Drive

```{r}

# ===== Logger Data ===== #
# Generate filename with today's date
today <- Sys.Date()
csv_filename <- paste0("kelp_index_combined_sensor_data_", today, ".csv")
rds_filename <- paste0("kelp_index_combined_sensor_data_", today, ".rds")

# Create temporary CSV file
temp_csv <- tempfile(fileext = ".csv")
write_csv(data, temp_csv)

# Upload CSV to Google Drive
drive_upload(media = temp_csv,
             name = csv_filename,
             path = as_id("1uGfyiyj-xAdy6xM2j81l7jDZK9SgNBw6"),
             overwrite = TRUE)

# Also upload RDS version
temp_rds <- tempfile(fileext = ".rds")
saveRDS(data, temp_rds)
drive_upload(media = temp_csv,
             name = rds_filename,
             path = as_id("1uGfyiyj-xAdy6xM2j81l7jDZK9SgNBw6"),
             overwrite = TRUE)


# ===== List of processed files ===== #
processed_filename <- paste0("processed_files_", today, ".csv")
processed_files <- read_rds(here("data", "processed_files.rds"))
processed_files <- as.data.frame(processed_files)

# Create temporary CSV file
temp_csv <- tempfile(fileext = ".csv")
write_csv(processed_files, temp_csv)

# Upload CSV to Google Drive
drive_upload(media = temp_csv,
             name = processed_filename,
             path = as_id("1uGfyiyj-xAdy6xM2j81l7jDZK9SgNBw6"),
             overwrite = TRUE)

# Clean up temp files
unlink(temp_csv)
unlink(temp_rds)
```

# Visual Check

The final, optional step is to visually check the data.

#### Tidbit Temperature

Surface:

```{r}
#| code-fold: true
# Surface temperature by site
data |>
  filter(position == "surface") |>
  ggplot() +
  geom_point(aes(x = datetime, y = tidbit_temp_c, color = temp_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "SST by Site",
       x = "Date",
       y = "Temperature (°C)") +
  theme_minimal()

```

#### pH

Surface:

```{r}
#| code-fold: true
# pH surface
data |>
  filter(position == "surface") |>
  ggplot() +
  geom_point(aes(x = datetime, y = pH, color = ph_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Surface pH by Site",
       x = "Date",
       y = "pH") +
  theme_minimal()

```

Bottom:

```{r}
#| code-fold: true
# pH bottom
data |>
  filter(position == "bottom") |>
  ggplot() +
  geom_point(aes(x = datetime, y = pH, color = ph_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "pH at Bottom by Site",
       x = "Date",
       y = "pH") +
  theme_minimal()

```

#### Dissolved Oxygen

Surface:

```{r}
#| code-fold: true
# DO surface
# Raw
data |>
  filter(position == "surface") |>
  ggplot() +
  geom_point(aes(x = datetime, y = do_conc_mg_per_L, color = do_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Dissolved Oxygen at Surface by Site",
       x = "Date",
       y = "Dissolved Oxygen (mg/L)") +
  theme_minimal()


# No values below zero
data |>
  filter(position == "surface") |>
  filter(do_conc_mg_per_L >= 0) |>
  ggplot() +
  geom_point(aes(x = datetime, y = do_conc_mg_per_L, color = do_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Dissolved Oxygen at Surface by Site (Filtered to >= 0)",
       x = "Date",
       y = "Dissolved Oxygen (mg/L)") +
  theme_minimal()
```

Bottom:

```{r}
#| code-fold: true
# DO bottom
# Raw
data |>
  filter(position == "bottom") |>
  ggplot() +
  geom_point(aes(x = datetime, y = do_conc_mg_per_L, color = do_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Dissolved Oxygen at Bottom by Site",
       x = "Date",
       y = "Dissolved Oxygen (mg/L)") +
  theme_minimal()

# No values below zero
data |>
  filter(position == "bottom") |>
  filter(do_conc_mg_per_L >= 0) |>
  ggplot() +
  geom_point(aes(x = datetime, y = do_conc_mg_per_L, color = do_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Dissolved Oxygen at Bottom by Site (Filtered to >= 0)",
       x = "Date",
       y = "Dissolved Oxygen (mg/L)") +
  theme_minimal()

```

#### Conductivity

Surface:

```{r}
#| code-fold: true
# CON surface
data |>
  filter(position == "surface") |>
  ggplot() +
  geom_point(aes(x = datetime, y = high_range_microsiemens_per_cm, color = con_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Conductivity at Surface by Site",
       x = "Date",
       y = "Conductivity (µS/cm)") +
  theme_minimal()

```

Bottom:

```{r}
#| code-fold: true
# CON bottom
data |>
  filter(position == "bottom") |>
  ggplot() +
  geom_point(aes(x = datetime, y = high_range_microsiemens_per_cm, color = con_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Conductivity at Bottom by Site",
       x = "Date",
       y = "Conductivity (µS/cm)") +
  theme_minimal()

```

#### Water Level

Bottom:

```{r}
#| code-fold: true
# WL bottom
data |>
  filter(position == "bottom") |>
  ggplot() +
  geom_point(aes(x = datetime, y = abs_pres_kpa, color = wl_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "Water Level at Bottom by Site",
       x = "Date",
       y = "Absolute Pressure (kpa)") +
  theme_minimal()

```

#### Light Intensity (PAR)

Bottom:

```{r}
#| code-fold: true
# PAR bottom (raw)
data |>
  filter(position == "bottom") |>
  ggplot() +
  geom_point(aes(x = datetime, y = raw_integrating_light, color = par_logger_id), size = 0.1) +
  facet_wrap(~site) +
  labs(title = "PAR Raw at Bottom by Site",
       x = "Date",
       y = "Raw Integrating Light") +
  theme_minimal()

```

#### Temp All Instruments

Surface:

```{r}
#| code-fold: true
# Raw


possible_temp_cols <- c("tidbit_temp_c", "ph_temp_c", "do_temp_c", "wl_temp_c", "con_temp_c")

data |>
  select("site", "position", "datetime", any_of(possible_temp_cols)) |>
  pivot_longer(
    cols = c(any_of(possible_temp_cols)),
    names_to = "temp_sensor_type",
    values_to = "temperature_c"
  ) |>
  filter(position == "surface") |>
  ggplot(aes(x = datetime, y = temperature_c, color = temp_sensor_type)) +
  geom_line(alpha = 0.7) +
  facet_wrap(~site) +
  labs(
    title = "Temperature Measurements at Surface by Site and Sensor Type",
    x = "Date/Time", 
    y = "Temperature (°C)",
    color = "Sensor Type"
  ) +
  theme_minimal()

# Filtered
data |>
  select("site", "position", "datetime", any_of(possible_temp_cols)) |>
  pivot_longer(
    cols = c(any_of(possible_temp_cols)),
    names_to = "temp_sensor_type",
    values_to = "temperature_c"
  ) |>
  filter(position == "surface",
         temperature_c >= 0,
         temperature_c <= 25) |>
  ggplot(aes(x = datetime, y = temperature_c, color = temp_sensor_type)) +
  geom_line(alpha = 0.7) +
  facet_wrap(~site) +
  labs(
    title = "Temperature Measurements at Surface by Site and Sensor Type",
    subtitle = "Filtered between 0 and 25 °C",
    x = "Date/Time", 
    y = "Temperature (°C)",
    color = "Sensor Type"
  ) +
  theme_minimal()
```

Bottom:

```{r}
#| code-fold: true
# Raw
data |>
  select("site", "position", "datetime", any_of(possible_temp_cols)) |>
  pivot_longer(
    cols = c(any_of(possible_temp_cols)),
    names_to = "temp_sensor_type",
    values_to = "temperature_c"
  ) |>
  filter(position == "bottom") |>
  ggplot(aes(x = datetime, y = temperature_c, color = temp_sensor_type)) +
  geom_line(alpha = 0.5) +
  facet_wrap(~site) +
  labs(
    title = "Temperature Measurements at Bottom by Site and Sensor Type",
    x = "Date/Time", 
    y = "Temperature (°C)",
    color = "Sensor Type"
  ) +
  theme_minimal()

# Filtered
data |>
  select("site", "position", "datetime", any_of(possible_temp_cols)) |>
  pivot_longer(
    cols = c(any_of(possible_temp_cols)),
    names_to = "temp_sensor_type",
    values_to = "temperature_c"
  ) |>
  filter(position == "bottom",
         temperature_c >= 0,
         temperature_c <= 25) |>
  ggplot(aes(x = datetime, y = temperature_c, color = temp_sensor_type)) +
  geom_line(alpha = 0.5) +
  facet_wrap(~site) +
  labs(
    title = "Temperature Measurements at Bottom by Site and Sensor Type",
    subtitle = "Filtered between 0 and 25 °C",
    x = "Date/Time", 
    y = "Temperature (°C)",
    color = "Sensor Type"
  ) +
  theme_minimal()
```
